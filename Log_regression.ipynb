{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install ucimlrepo"
      ],
      "metadata": {
        "id": "u4lqHN-QRkBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "wine_quality = fetch_ucirepo(id=186)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X= wine_quality.data.features\n",
        "Y = wine_quality.data.targets\n",
        "X"
      ],
      "metadata": {
        "id": "mMGtUwjlRki-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x.iloc[1598]\n",
        "# y.iloc[1598]\n",
        "x = X.iloc[:1599]\n",
        "y = Y.iloc[:1599]\n"
      ],
      "metadata": {
        "id": "C2eTpm4-tBrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x)"
      ],
      "metadata": {
        "id": "m99O3lvktBop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.iloc[1598],y.iloc[1598]"
      ],
      "metadata": {
        "id": "oKDKzRzntBmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature=[]\n",
        "for i in x:\n",
        "  print(i)\n",
        "  feature.append(i)"
      ],
      "metadata": {
        "id": "-X8dvNFsShHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "3hMTiMbVSrVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature"
      ],
      "metadata": {
        "id": "q_GdGH25XX6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y['quality'].value_counts()"
      ],
      "metadata": {
        "id": "qqwNF5XamBZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert all the values in the quality attribute to 0 (bad) if the value is less than or equal to 6,\n",
        "and to 1 (good) otherwise. Normalise all the other attributes between 0 and 1 by min-max scaling.\n",
        "Use this dataset (dataset A) for Logistic Regression**"
      ],
      "metadata": {
        "id": "MDI_2MDTl_Rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  a=y['quality'].values\n",
        "#  a\n",
        "#  y=a"
      ],
      "metadata": {
        "id": "6c696HQfl-58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=y['quality'].values\n",
        "a\n",
        "y=a\n",
        "for i in range(len(y)):\n",
        "  if y[i]<6:\n",
        "    y[i]=0\n",
        "  else:\n",
        "    y[i]=1"
      ],
      "metadata": {
        "id": "gNgAD64AgHgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one =0\n",
        "zero=0\n",
        "for i in y:\n",
        "  if i==1:\n",
        "    one+=1\n",
        "  else:\n",
        "    zero+=1\n",
        "print(\" 0 :\",zero)\n",
        "print(\" 1 :\",one)"
      ],
      "metadata": {
        "id": "e_2JqvZc5J26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=[]\n",
        "for i in range(len(feature)):\n",
        "  xi=x[feature[i]].values\n",
        "  data.append(xi)"
      ],
      "metadata": {
        "id": "f9uM6SazgmYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data),len(feature),len(data[0])"
      ],
      "metadata": {
        "id": "v4jxPgWGhAOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0][3],data[4][0]"
      ],
      "metadata": {
        "id": "Dqa3G8uFigCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HC4yW6SLFEe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(data)):\n",
        "  z=data[i]\n",
        "  mn=min(z)\n",
        "  mx=max(z)\n",
        "  diff=mx-mn\n",
        "  for j in range(len(z)):\n",
        "    data[i][j]=(z[j]-mn)/diff\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "13dbScz9i5z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0][3],data[4][0]"
      ],
      "metadata": {
        "id": "2jAOzo44k7kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "id": "JPalFNRLspHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data = data.astype(float)\n",
        "# y = y.astype(int)\n",
        "data=np.array(data).T\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=42)\n",
        "print(len(x_train),len(y_train),len(x_test),len(y_test))\n"
      ],
      "metadata": {
        "id": "dIOtxcvBMZwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0AGHps57MZnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(p):\n",
        "  val=1/(1 + np.exp(-p))\n",
        "\n",
        "  return val"
      ],
      "metadata": {
        "id": "-aLuT8yrVXBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(w,x,i):\n",
        "  p=w[0]\n",
        "  for j in range(1,len(w)):\n",
        "    p+=w[j]*x[i][j-1]\n",
        "  p=sigmoid(p)\n",
        "  return p\n"
      ],
      "metadata": {
        "id": "APrBv2lxlpk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regg(x,y,m,fs):\n",
        "  # m is number of examples\n",
        "  w=[1]*(fs+1) #fs is number of feature\n",
        "  for j in range(1000):\n",
        "\n",
        "    totalerror=[0]*(fs+1)\n",
        "\n",
        "    for i in range(m):\n",
        "      p=predict(w,x,i)\n",
        "      error=p-y[i]\n",
        "      totalerror[0]=totalerror[0]+error\n",
        "      for k in range(1,len(totalerror)):\n",
        "        totalerror[k]+= error*x[i][k-1]\n",
        "\n",
        "    for k in range(len(w)):\n",
        "      w[k]=w[k]-(0.05*totalerror[k])/m\n",
        "\n",
        "  return w"
      ],
      "metadata": {
        "id": "aU_wdzyit-Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w=logistic_regg(x_train,y_train,len(x_train),len(data[0]))"
      ],
      "metadata": {
        "id": "JHTbiRfnIwGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w"
      ],
      "metadata": {
        "id": "u193bLfjRHGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans=[]\n",
        "for i in w:\n",
        "  ans.append(i.item())\n",
        "for i in range(len(ans)):\n",
        "  print(f\"w{i} : \",ans[i])"
      ],
      "metadata": {
        "id": "W9-lkJmhRTRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_iHoRiK7Mfja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hk4ToTotMfeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testing(w,x,y):\n",
        "  m=len(x)\n",
        "  cp=0\n",
        "  wp=0\n",
        "  tp=0\n",
        "  tn=0\n",
        "  fp=0\n",
        "  fn=0\n",
        "  z=0\n",
        "  one=0\n",
        "  for i in range(m):\n",
        "\n",
        "    p=predict(w,x,i)\n",
        "\n",
        "    if(p>0.5):\n",
        "      p=1\n",
        "    else:\n",
        "      p=0\n",
        "\n",
        "    if(p==1 and y[i]==1):\n",
        "      tp+=1\n",
        "    elif(p==1 and y[i]==0):\n",
        "      fp+=1\n",
        "    elif(p==0 and y[i]==1):\n",
        "      fn+=1\n",
        "    else:\n",
        "      tn+=1\n",
        "\n",
        "    if(p == y[i]):\n",
        "      if(p==1):\n",
        "        one+=1\n",
        "      cp+=1\n",
        "    else:\n",
        "      if(p==1):\n",
        "        one+=1\n",
        "      wp+=1\n",
        "  precision=(tp*100)/(tp+fp)\n",
        "  recall=(tp*100)/(tp+fn)\n",
        "\n",
        "  print(tp,tn,fp,fn,one)\n",
        "\n",
        "  print(\"Correct Prediction : \", cp)\n",
        "  print(\"Wrong Prediction   : \", wp)\n",
        "\n",
        "  print(f\"Accuracy           :  {((cp/m)*100):.2f}%\")\n",
        "  print(f\"Precision          :  {precision:.2f}\")\n",
        "  print(f\"Recall             :  {recall:.2f}\")\n",
        "  print()\n",
        "  print()\n",
        "  # return ans"
      ],
      "metadata": {
        "id": "WZN4gnl1R7Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans=testing(w,x_test,y_test)\n",
        "ans"
      ],
      "metadata": {
        "id": "LOxMdLWKWWtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q92wcRTLGstk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test out the implementation of Logistic Regression from the scikit-learn package, using saga solver and no regularization penalty**"
      ],
      "metadata": {
        "id": "A-OGcEnFf4D_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model= LogisticRegression(solver='saga',max_iter=1000, penalty=None)\n",
        "model.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "M266Sv-Yf-oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc=model.score(x_test,y_test)\n",
        "print(f\"Accuracy without 3 fold : {acc*100:.2f} %\")"
      ],
      "metadata": {
        "id": "qXO-K9FFgSWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cb8yHEYcHmzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy :\", acc)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall   :\", recall)"
      ],
      "metadata": {
        "id": "Oqho8x3rh9sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wBqzimx9-7_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Cross-validate both the classifiers with 3-folds and print the mean accuracy, precision, and recall for the class 1 (good) for both the classifiers. You may or may not use the scikit-learn implementations for computing these metrics and cross-validation.**"
      ],
      "metadata": {
        "id": "XtMr8aGdhxFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "def k_fold(k,data,y):\n",
        "  kf=KFold(n_splits=k,shuffle=True)\n",
        "  return kf"
      ],
      "metadata": {
        "id": "TpObzmtdg_yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=k_fold(3,data,y)\n",
        "x"
      ],
      "metadata": {
        "id": "ZQNxXfQZlJ0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy=[]\n",
        "for itrain,itest in x.split(data):\n",
        "  x_train  = data[itrain]\n",
        "  x_test = data[itest]\n",
        "  y_train = y[itrain]\n",
        "  y_test =  y[itest]\n",
        "  w=logistic_regg(x_train,y_train,len(x_train),len(data[0]))\n",
        "  acc=testing(w,x_test,y_test)\n",
        "  accuracy.append(acc)"
      ],
      "metadata": {
        "id": "EHIscAFwnsMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy2=[]\n",
        "p=[]\n",
        "r=[]\n",
        "for itrain,itest in x.split(data):\n",
        "  x_train, x_test = data[itrain], data[itest]\n",
        "  y_train, y_test = y[itrain], y[itest]\n",
        "  model= LogisticRegression(solver='saga',max_iter=1000, penalty=None)\n",
        "  model.fit(x_train,y_train)\n",
        "  acc=model.score(x_test,y_test)\n",
        "  y_pred = model.predict(x_test) # Calculate y_pred for the current test set\n",
        "  precision = precision_score(y_test, y_pred)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  accuracy2.append(acc*100)\n",
        "  p.append(precision)\n",
        "  r.append(recall)"
      ],
      "metadata": {
        "id": "l4aaAEnnp4wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy2,p,r"
      ],
      "metadata": {
        "id": "9b9EK3y0siet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean, std\n",
        "print(mean(accuracy2))\n",
        "print(mean(p) *100)\n",
        "print(mean(r) *100)"
      ],
      "metadata": {
        "id": "H0yJwQnQBB3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e8PhRvQPvN3U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}